{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration\n",
    "Author contact: [adam_lewandowski_1998@outlook.com](mailto:adam_lewandowski_1998@outlook.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itables import init_notebook_mode\n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_table():\n",
    "    path = \"../Webscrappers/out/results_classification.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_table()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unimportant labels with recipies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Favorites \", \"*Member Recipes\"])\n",
    "to_remove_empty = (df[df.columns[1:]] == 0).all(axis=1)\n",
    "df = df[~to_remove_empty]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show information about non-null counts with assigned types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load spacy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "docs = list(nlp.pipe(df.object))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas():\n",
    "    lemma = docs[0][:].lemma_\n",
    "\n",
    "    to_show = []\n",
    "    for d in docs:\n",
    "        l = str(d[:].lemma_)\n",
    "        t = str(d[:])\n",
    "        if l != t:\n",
    "            to_show.append({\"lemma\": l, \"original\": t})\n",
    "\n",
    "    df = pd.DataFrame(to_show)\n",
    "    return df\n",
    "\n",
    "\n",
    "show_lemmas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_entities():\n",
    "    lemma = docs[0][:].lemma_\n",
    "\n",
    "    entities = pd.DataFrame(\n",
    "        [\n",
    "            {\"doc_id\": doc_id, \"entity\": str(e), \"type\": str(e.label_)}\n",
    "            for doc_id, d in enumerate(docs)\n",
    "            for e in d.ents\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return entities\n",
    "\n",
    "\n",
    "entities = show_entities()\n",
    "entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entities types counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities.type.value_counts(normalize=True).round(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entities with types counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities[[\"entity\", \"type\"]].value_counts(normalize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show most similar docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def show_similar_docs():\n",
    "    vecs = np.array([d.vector / d.vector_norm for d in docs])\n",
    "\n",
    "    similarities = vecs @ vecs.T\n",
    "    diagonal = np.eye(len(similarities)).astype(bool)\n",
    "    similarities[diagonal] = 0\n",
    "    most_similar_args = np.argwhere(similarities > 0.9)\n",
    "\n",
    "    text = np.array([str(d) for d in docs])\n",
    "    df = pd.DataFrame(\n",
    "        text[most_similar_args], columns=[\"doc_1\", \"doc_2\"]\n",
    "    ).query(\"doc_1 != doc_2\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "show_similar_docs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "X = df.object.values\n",
    "\n",
    "y = df[df.columns[1:]]\n",
    "y = [\n",
    "    [cat for cat, val in row.items() if val > 0] for row in y.to_dict(\"records\")\n",
    "]\n",
    "y_encoder = MultiLabelBinarizer()\n",
    "y = y_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "def lemmatize(x):\n",
    "    import spacy\n",
    "\n",
    "    required_pos = (\"NOUN\", \"VERB\", \"PROPN\", \"ADJ\")\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    docs = (d for d in nlp.pipe(x))\n",
    "    lemmas = [\n",
    "        [\n",
    "            tok.lemma_.lower()\n",
    "            for tok in d\n",
    "            if tok.is_alpha and tok.pos_ in required_pos\n",
    "        ]\n",
    "        for d in docs\n",
    "    ]\n",
    "    # remove empty and convert to string\n",
    "    lemmas = [\" \".join(d) for d in lemmas if len(d) > 0]\n",
    "    return lemmas\n",
    "\n",
    "\n",
    "preprocessing = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", FunctionTransformer(lemmatize),),\n",
    "        (\n",
    "            \"vectorizer\",\n",
    "            TfidfVectorizer(binary=False, lowercase=False, norm=\"l1\"),\n",
    "        ),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")\n",
    "model_1 = LogisticRegression(\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\",\n",
    "    penalty=\"elasticnet\",\n",
    "    l1_ratio=0.2,\n",
    "    solver=\"saga\",\n",
    "    max_iter=10_000\n",
    ")\n",
    "model_2 = SVC(probability=True, kernel='sigmoid')\n",
    "voting = VotingClassifier(\n",
    "    estimators=[(\"model_1\", model_1), (\"model_2\", model_2)],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "model_ensemble = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessing),\n",
    "        (\"multi-class mult-label\", MultiOutputClassifier(voting, n_jobs=-1)),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")\n",
    "model_ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model_ensemble.fit(X, y)\n",
    "print(m.score(X, y))\n",
    "y_hat = m.predict([\"christmas cake chicken salad\", \"lite pancake\", \"salad\"])\n",
    "y_encoder.inverse_transform(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the mean results of `cross validation` we will first get the best architecture, then extract the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    train_sizes, train_scores, valid_scores = learning_curve(\n",
    "        model_ensemble, X, y, n_jobs=-1, verbose=True, shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture selection based on training score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(train_scores, 0).mean(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture selection based on test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(valid_scores, 0).mean(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def get_best_cv_model(model):\n",
    "    best = {'score': 0, 'model': None}\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "\n",
    "        if score > best['score']:\n",
    "            best = {'score': score, 'model': model}\n",
    "\n",
    "    return best\n",
    "\n",
    "best_model = get_best_cv_model(model_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "setattr(best_model['model'], 'y_encoder', y_encoder)\n",
    "joblib.dump(best_model['model'], '../out/recipy_category_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if we can load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def lemmatize(x):\n",
    "    import spacy\n",
    "\n",
    "    required_pos = (\"NOUN\", \"VERB\", \"PROPN\", \"ADJ\")\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    docs = (d for d in nlp.pipe(x))\n",
    "    lemmas = [\n",
    "        [\n",
    "            tok.lemma_.lower()\n",
    "            for tok in d\n",
    "            if tok.is_alpha and tok.pos_ in required_pos\n",
    "        ]\n",
    "        for d in docs\n",
    "    ]\n",
    "    # remove empty and convert to string\n",
    "    lemmas = [\" \".join(d) for d in lemmas if len(d) > 0]\n",
    "    return lemmas\n",
    "\n",
    "clf = joblib.load('../out/recipy_category_model.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = clf.predict(['chicken salad', 'christmas lite salad'])\n",
    "clf.y_encoder.inverse_transform(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d71527e0dd44f795681ff70e41af4afeb0c5f4d47a79545f42bdef8e803f147b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
